{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FIleuCAjoFD8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0koUcJMJpEBD"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'_thread.RLock' object has no attribute '_recursion_count'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m train_datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      3\u001b[0m     rescale\u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m,\n\u001b[1;32m      4\u001b[0m     shear_range\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,\n\u001b[1;32m      5\u001b[0m     zoom_range\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, \n\u001b[1;32m      6\u001b[0m     horizontal_flip\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[39m# The rescale option normalizes the pixel values i.e how black/white it is (how bright that pixel is). for easier processing in the CNN\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m training_set \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[1;32m     10\u001b[0m     directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./dataset/training_set/\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     target_size\u001b[39m=\u001b[39m(\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m),\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     13\u001b[0m     class_mode\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[39m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1649\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[1;32m   1650\u001b[0m         directory,\n\u001b[1;32m   1651\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1652\u001b[0m         target_size\u001b[39m=\u001b[39mtarget_size,\n\u001b[1;32m   1653\u001b[0m         color_mode\u001b[39m=\u001b[39mcolor_mode,\n\u001b[1;32m   1654\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39mkeep_aspect_ratio,\n\u001b[1;32m   1655\u001b[0m         classes\u001b[39m=\u001b[39mclasses,\n\u001b[1;32m   1656\u001b[0m         class_mode\u001b[39m=\u001b[39mclass_mode,\n\u001b[1;32m   1657\u001b[0m         data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format,\n\u001b[1;32m   1658\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1659\u001b[0m         shuffle\u001b[39m=\u001b[39mshuffle,\n\u001b[1;32m   1660\u001b[0m         seed\u001b[39m=\u001b[39mseed,\n\u001b[1;32m   1661\u001b[0m         save_to_dir\u001b[39m=\u001b[39msave_to_dir,\n\u001b[1;32m   1662\u001b[0m         save_prefix\u001b[39m=\u001b[39msave_prefix,\n\u001b[1;32m   1663\u001b[0m         save_format\u001b[39m=\u001b[39msave_format,\n\u001b[1;32m   1664\u001b[0m         follow_links\u001b[39m=\u001b[39mfollow_links,\n\u001b[1;32m   1665\u001b[0m         subset\u001b[39m=\u001b[39msubset,\n\u001b[1;32m   1666\u001b[0m         interpolation\u001b[39m=\u001b[39minterpolation,\n\u001b[1;32m   1667\u001b[0m         dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype,\n\u001b[1;32m   1668\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/preprocessing/image.py:569\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(classes)\n\u001b[1;32m    567\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_indices \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(classes, \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(classes))))\n\u001b[0;32m--> 569\u001b[0m pool \u001b[39m=\u001b[39m multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mThreadPool()\n\u001b[1;32m    571\u001b[0m \u001b[39m# Second, build an index of the images\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39m# in the different class subfolders.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m results \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/pool.py:930\u001b[0m, in \u001b[0;36mThreadPool.__init__\u001b[0;34m(self, processes, initializer, initargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, processes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, initializer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, initargs\u001b[39m=\u001b[39m()):\n\u001b[0;32m--> 930\u001b[0m     Pool\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, processes, initializer, initargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/pool.py:196\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_taskqueue \u001b[39m=\u001b[39m queue\u001b[39m.\u001b[39mSimpleQueue()\n\u001b[1;32m    193\u001b[0m \u001b[39m# The _change_notifier queue exist to wake up self._handle_workers()\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m# when the cache (self._cache) is empty or when there is a change in\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# the _state variable of the thread that runs _handle_workers.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_change_notifier \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ctx\u001b[39m.\u001b[39mSimpleQueue()\n\u001b[1;32m    197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m _PoolCache(notifier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_change_notifier)\n\u001b[1;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maxtasksperchild \u001b[39m=\u001b[39m maxtasksperchild\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:113\u001b[0m, in \u001b[0;36mBaseContext.SimpleQueue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Returns a queue object'''\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mqueues\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleQueue\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m SimpleQueue(ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_context())\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/queues.py:341\u001b[0m, in \u001b[0;36mSimpleQueue.__init__\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, ctx):\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_writer \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mPipe(duplex\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mLock()\n\u001b[1;32m    342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mpoll\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwin32\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:68\u001b[0m, in \u001b[0;36mBaseContext.Lock\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Returns a non-recursive lock object'''\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msynchronize\u001b[39;00m \u001b[39mimport\u001b[39;00m Lock\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m Lock(ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_context())\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/synchronize.py:169\u001b[0m, in \u001b[0;36mLock.__init__\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, ctx):\n\u001b[0;32m--> 169\u001b[0m     SemLock\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, SEMAPHORE, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, ctx\u001b[39m=\u001b[39mctx)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/synchronize.py:80\u001b[0m, in \u001b[0;36mSemLock.__init__\u001b[0;34m(self, kind, value, maxvalue, ctx)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_semlock\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[39m# We only get here if we are on Unix with forking\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[39m# disabled.  When the object is garbage collected or the\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[39m# process shuts down we unlink the semaphore name\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresource_tracker\u001b[39;00m \u001b[39mimport\u001b[39;00m register\n\u001b[0;32m---> 80\u001b[0m     register(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_semlock\u001b[39m.\u001b[39mname, \u001b[39m\"\u001b[39m\u001b[39msemaphore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m     util\u001b[39m.\u001b[39mFinalize(\u001b[39mself\u001b[39m, SemLock\u001b[39m.\u001b[39m_cleanup, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_semlock\u001b[39m.\u001b[39mname,),\n\u001b[1;32m     82\u001b[0m                   exitpriority\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/resource_tracker.py:174\u001b[0m, in \u001b[0;36mResourceTracker.register\u001b[0;34m(self, name, rtype)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister\u001b[39m(\u001b[39mself\u001b[39m, name, rtype):\n\u001b[1;32m    173\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Register name of resource with resource tracker.'''\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send(\u001b[39m'\u001b[39m\u001b[39mREGISTER\u001b[39m\u001b[39m'\u001b[39m, name, rtype)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/resource_tracker.py:182\u001b[0m, in \u001b[0;36mResourceTracker._send\u001b[0;34m(self, cmd, name, rtype)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_send\u001b[39m(\u001b[39mself\u001b[39m, cmd, name, rtype):\n\u001b[1;32m    181\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensure_running()\n\u001b[1;32m    183\u001b[0m     \u001b[39mexcept\u001b[39;00m ReentrantCallError:\n\u001b[1;32m    184\u001b[0m         \u001b[39m# The code below might or might not work, depending on whether\u001b[39;00m\n\u001b[1;32m    185\u001b[0m         \u001b[39m# the resource tracker was already running and still alive.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[39m# Better warn the user.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[39m# (XXX is warnings.warn itself reentrant-safe? :-)\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    189\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResourceTracker called reentrantly for resource cleanup, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhich is unsupported. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mrtype\u001b[39m}\u001b[39;00m\u001b[39m object \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m might leak.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/resource_tracker.py:100\u001b[0m, in \u001b[0;36mResourceTracker.ensure_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Make sure that resource tracker process is running.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[39mThis can be run from any process.  Usually a child process will use\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mthe resource created by its parent.'''\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39m_recursion_count() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    101\u001b[0m         \u001b[39m# The code below is certainly not reentrant-safe, so bail out\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reentrant_call_error()\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fd \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         \u001b[39m# resource tracker was launched before, is it still running?\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_thread.RLock' object has no attribute '_recursion_count'"
          ]
        }
      ],
      "source": [
        "# We preprocess the images dataset to introduce some variety in images such as zoomed, sheared, flipped etc. to avoid overfitting the model\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1. / 255,\n",
        "    shear_range= 0.2,\n",
        "    zoom_range= 0.2, \n",
        "    horizontal_flip= True,\n",
        ")\n",
        "# The rescale option normalizes the pixel values i.e how black/white it is (how bright that pixel is). for easier processing in the CNN\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    directory='./dataset/training_set/',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode= 'binary'\n",
        ")\n",
        "# Target_size is the size(h,w) of the images before feeding it to the CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SH4WzfOhpKc3"
      },
      "outputs": [],
      "source": [
        "# we are only rescaling but not applying any transformations\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale= 1. / 255,\n",
        ")\n",
        "test_set = train_datagen.flow_from_directory(\n",
        "    directory='dataset/test_set',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode= 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters= 32, input_shape=[64,64,3], kernel_size = 3, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters= 32, kernel_size = 3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 128, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One neuron for the output either cat or dog\n",
        "cnn.add(tf.keras.layers.Dense(units = 1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "# Load image as PIL format\n",
        "test_image = image.load_img('dataset/training_set/single_prediction/cat_or_dog_1.jpg', target_size = (64,64))\n",
        "# convert PIL format into an array\n",
        "test_image = image.image_to_array(test_image)\n",
        "# we trained our cnn in a batch so we cannot directly feed it a single image\n",
        "# we add another dimension to our array coresponding to a batch\n",
        "test_image = np.expand_dims(test_image, axis = 0) # new dimension is added at 0th positon of the array\n",
        "print(test_image)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "# first 0 refers to the batch and the second 0 refers to the prediction"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "convolutional_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
